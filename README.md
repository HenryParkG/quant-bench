# quant-bench

`quant-bench`ëŠ” ë‹¤ì–‘í•œ **ë”¥ëŸ¬ë‹ ëª¨ë¸ ì–‘ìí™”(Quantization) ê¸°ë²•**ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ë¹„êµí•˜ê¸° ìœ„í•œ ì‹¤í—˜ìš© ë ˆí¬ì§€í† ë¦¬ì…ë‹ˆë‹¤.  
Post-Training Quantization(PTQ), Quantization-Aware Training(QAT) ë“±ì„ ì§€ì›í•˜ë©°, ëª¨ë¸ ì •í™•ë„, í¬ê¸°, ì†ë„ ë“± ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë²¤ì¹˜ë§ˆí‚¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“‚ ë ˆí¬ì§€í† ë¦¬ êµ¬ì¡°

<pre>
quant-bench/
â”‚
â”œâ”€â”€ datasets/ # ë°ì´í„°ì…‹ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ë° ë‹¤ìš´ë¡œë“œ
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ imagenet.py
â”‚ â”œâ”€â”€ cifar.py
â”‚ â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ models/ # ì›ë³¸/ì‚¬ì „ í•™ìŠµ ëª¨ë¸ê³¼ ë˜í¼
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ resnet.py
â”‚ â”œâ”€â”€ vit.py
â”‚ â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ quantization/ # ë‹¤ì–‘í•œ ì–‘ìí™” ê¸°ë²• êµ¬í˜„
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ ptq/ # Post-training Quantization
â”‚ â”‚ â”œâ”€â”€ minmax.py
â”‚ â”‚ â””â”€â”€ histogram.py
â”‚ â”œâ”€â”€ qat/ # Quantization-aware Training
â”‚ â”‚ â”œâ”€â”€ fake_quant.py
â”‚ â”‚ â””â”€â”€ trainer.py
â”‚ â””â”€â”€ utils.py # ê³µí†µ í•¨ìˆ˜ (scale, bit config ë“±)
â”‚
â”œâ”€â”€ benchmarks/ # ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ run_experiment.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â””â”€â”€ compare_results.py
â”‚
â”œâ”€â”€ configs/ # ì‹¤í—˜ ì„¤ì • YAML íŒŒì¼
â”‚ â”œâ”€â”€ resnet_ptq.yaml
â”‚ â”œâ”€â”€ vit_qat.yaml
â”‚ â””â”€â”€ default.yaml
â”‚
â”œâ”€â”€ results/ # ì‹¤í—˜ ê²°ê³¼ ì €ì¥
â”‚ â”œâ”€â”€ logs/
â”‚ â””â”€â”€ plots/
â”‚
â”œâ”€â”€ utils/ # ê³µìš© ìœ í‹¸ë¦¬í‹°
â”‚ â”œâ”€â”€ logger.py
â”‚ â”œâ”€â”€ metrics.py
â”‚ â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
</pre>

---

## âš¡ ì£¼ìš” ê¸°ëŠ¥

- ë‹¤ì–‘í•œ ì–‘ìí™” ê¸°ë²• ì§€ì›
  - **PTQ(Post-Training Quantization)**: Min-Max, Histogram ê¸°ë°˜
  - **QAT(Quantization-Aware Training)**: Fake Quantization ë“±
- ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›
  - ResNet, Vision Transformer ë“±
- ë²¤ì¹˜ë§ˆí¬ ìë™í™”
  - ëª¨ë¸ë³„ ì •í™•ë„, ëª¨ë¸ í¬ê¸°, ì—°ì‚°ëŸ‰ ë¹„êµ
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ êµ¬ì¡°
  - YAML ê¸°ë°˜ ì„¤ì • íŒŒì¼ë¡œ íŒŒë¼ë¯¸í„° ê´€ë¦¬
- ê²°ê³¼ ì‹œê°í™”
  - Accuracy/Size/Latency ë¹„êµ ì°¨íŠ¸ ìƒì„±

---

## ğŸ›  ì„¤ì¹˜

```bash
git clone https://github.com/henryparkg/quant-bench.git
cd quant-bench
python -m venv venv
source venv/bin/activate  # Linux/Mac
# .\venv\Scripts\activate  # Windows
pip install -r requirements.txt

```

ğŸ— ì‚¬ìš©ë²•
1ï¸âƒ£ ë°ì´í„°ì…‹ ì¤€ë¹„

datasets/ í´ë”ì—ì„œ ì œê³µí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬

from datasets.cifar import get_cifar10
train_loader, test_loader = get_cifar10(batch_size=64)

2ï¸âƒ£ ëª¨ë¸ ë¡œë“œ

models/ í´ë”ì˜ ëª¨ë¸ ë˜í¼ ì‚¬ìš©

from models.resnet import ResNet18
model = ResNet18(pretrained=True)

3ï¸âƒ£ ì–‘ìí™” ì ìš©
PTQ
from quantization.ptq.minmax import apply_minmax_quant
quantized_model = apply_minmax_quant(model, bit_width=8)

QAT
from quantization.qat.trainer import train_qat
qat_model = train_qat(model, train_loader, epochs=10)

4ï¸âƒ£ ì‹¤í—˜ ì‹¤í–‰

benchmarks/run_experiment.pyë¥¼ ì‚¬ìš©í•˜ì—¬ YAML ì„¤ì • íŒŒì¼ ê¸°ë°˜ ì‹¤í—˜

python benchmarks/run_experiment.py --config configs/resnet_ptq.yaml

5ï¸âƒ£ ê²°ê³¼ í™•ì¸

results/logs/ â†’ ì‹¤í—˜ ë¡œê·¸

results/plots/ â†’ Accuracy/Size/Latency ë¹„êµ ê·¸ë˜í”„

ğŸ“Š ì˜ˆì œ ê²°ê³¼ ì‹œê°í™”

Accuracy vs Bit-width

Model Size vs Accuracy

Latency Comparison

ìë™ìœ¼ë¡œ ê·¸ë˜í”„ ìƒì„± ê°€ëŠ¥, ì»¤ìŠ¤í…€ ì‹œê°í™”ëŠ” utils/visualization.py ì‚¬ìš©
